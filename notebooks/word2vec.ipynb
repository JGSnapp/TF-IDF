{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3527d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d76e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data = pd.read_csv(\"../data/output/train.csv\")\n",
    "test_data = pd.read_csv(\"../data/output/test.csv\")\n",
    "\n",
    "train_texs = train_data['text'].to_list()\n",
    "test_texs = test_data['text'].to_list()\n",
    "\n",
    "y_train = train_data['type'].to_list()\n",
    "y_test = test_data['type'].to_list()\n",
    "\n",
    "train_texts_tokenized = [text.lower().split() for text in train_texs]\n",
    "test_texts_tokenized = [text.lower().split() for text in test_texs]\n",
    "\n",
    "word2vec = Word2Vec(train_texts_tokenized, vector_size=300, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6be9f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence(tokens):\n",
    "    vecs = [word2vec.wv[w] for w in tokens if w in word2vec.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(300)\n",
    "\n",
    "X_train = np.array([vectorize_sentence(text) for text in train_texts_tokenized])\n",
    "X_test  = np.array([vectorize_sentence(text) for text in test_texts_tokenized])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae95bb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5453998797354179 0.4365493680245956\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter = 3000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd0ee397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "\n",
    "path = '../navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)\n",
    "\n",
    "def vectorize_sentence_2(sentence):\n",
    "    vecs = [navec.get(word) for word in sentence if word in navec]\n",
    "    return np.mean(vecs, axis = 0) if vecs else np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a5f2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_navec = np.array([vectorize_sentence_2(text) for text in train_texts_tokenized])\n",
    "X_test_navec = np.array([vectorize_sentence_2(text) for text in test_texts_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7644950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3018641010222489 0.1877558420591818\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=3000)\n",
    "logreg.fit(X_train_navec, y_train)\n",
    "y_pred_navec = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_navec)\n",
    "f1 = f1_score(y_test, y_pred_navec, average = 'macro')\n",
    "print(accuracy, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ac0986a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2760072158749248 0.10815268614514609\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "fasttext_model = FastText(sentences = train_texts_tokenized, vector_size = 300, window = 5, min_count = 1)\n",
    "\n",
    "def vectorize_sentence_3(tokens):\n",
    "    vecs = [fasttext_model.wv[w] for w in tokens if w in fasttext_model.wv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(300)\n",
    "\n",
    "X_train_fasttext = np.array([vectorize_sentence_3(text) for text in train_texts_tokenized])\n",
    "X_test_fasttext = np.array([vectorize_sentence_3(text) for text in test_texts_tokenized])\n",
    "\n",
    "logreg = LogisticRegression(max_iter=3000)\n",
    "logreg.fit(X_train_fasttext, y_train)\n",
    "y_pred_fasttext = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_fasttext)\n",
    "f1 = f1_score(y_test, y_pred_fasttext, average = 'macro')\n",
    "print(accuracy, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fd5edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import fasttext\n",
    "\n",
    "path = hf_hub_download(\"facebook/fasttext-ru-vectors\", filename=\"model.bin\")\n",
    "ft = fasttext.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54bed893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2760072158749248 0.10815268614514609\n"
     ]
    }
   ],
   "source": [
    "def vectorize_sentence_4(sentence):\n",
    "    vecs = [ft.get_word_vector(word) for word in sentence if word in ft.words]\n",
    "    return np.mean(vecs, axis = 0) if vecs else np.zeros(300)\n",
    "\n",
    "X_train_fasttext2 = np.array([vectorize_sentence_4(text) for text in train_texts_tokenized])\n",
    "X_test_fasttext2 = np.array([vectorize_sentence_4(text) for text in test_texts_tokenized])\n",
    "\n",
    "logreg = LogisticRegression(max_iter=3000)\n",
    "logreg.fit(X_train_fasttext2, y_train)\n",
    "y_pred_fasttext2 = logreg.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_fasttext2)\n",
    "f1 = f1_score(y_test, y_pred_fasttext2, average = 'macro')\n",
    "print(accuracy, f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
